{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from src.data.dataset import GlossSeq2PolishDataset\n",
    "from src.settings import MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_dataset = GlossSeq2PolishDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlossSeq2PolishRecord(gloss_sequence=[GlossAnnotationRecord(start=39040, end=39440, text='MYŚLEĆ 2.1 P:Z;L:Z (NA PRZEMIAN)', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15', dominant_hand=True), GlossAnnotationRecord(start=39440, end=39640, text='JAK 1.2 P:I;L:Ø', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15', dominant_hand=True), GlossAnnotationRecord(start=39640, end=39920, text='POMYSŁ 1.3 P:AZ;L:Ø', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15', dominant_hand=True), GlossAnnotationRecord(start=39920, end=40200, text='WSKAZ-JA 1.1 P:L;L;Ø (Z WIDOCZNYM KCIUKIEM)', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15', dominant_hand=True), GlossAnnotationRecord(start=40200, end=41120, text='MOŻNA 1.1 P:B;L:B  (MOŻE/MOŻLIWE)', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15', dominant_hand=True), GlossAnnotationRecord(start=39080, end=39800, text='Q: 5+5 (AWU/TAK MYŚLAŁEM, A OKAZAŁO SIĘ, ŻE JEST INACZEJ)', doc_filepath='/24/K66BF13-26_24_24_alarm.eaf', video_filename='K66BF13-26.mp4', task_label='24', dominant_hand=True), GlossAnnotationRecord(start=39800, end=40280, text='$:KL: A (WALIĆ/UDERZAĆ W GŁOWĘ/DRZWI)', doc_filepath='/24/K66BF13-26_24_24_alarm.eaf', video_filename='K66BF13-26.mp4', task_label='24', dominant_hand=True), GlossAnnotationRecord(start=40280, end=40880, text='NIC 1.2 P:C;L:Ø', doc_filepath='/24/K66BF13-26_24_24_alarm.eaf', video_filename='K66BF13-26.mp4', task_label='24', dominant_hand=True)], polish_annotation=PolishAnnotationRecord(start=39040, end=41120, text='Myślę, że mam inny pomysł, można?', doc_filepath='/15/K66BF13-26_15_15_signsNO.eaf', video_filename='K66BF13-26.mp4', task_label='15'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d773f63123d042418908f32043475f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SOURCE_LANG = \"gloss_pl\"\n",
    "TARGET_LANG = \"pl\"\n",
    "\n",
    "gen_kwargs = {\"pt_dataset\": pt_dataset, \"source_lang\": SOURCE_LANG, \"target_lang\": TARGET_LANG}\n",
    "\n",
    "def gen(pt_dataset, source_lang, target_lang):\n",
    "    for record in pt_dataset:\n",
    "        gloss_concatenated_text = \" \".join(\n",
    "            [g.text for g in record.gloss_sequence]\n",
    "        )\n",
    "        yield {\n",
    "            \"task_label\": record.polish_annotation.task_label,\n",
    "            \"translation\": {\n",
    "                source_lang: gloss_concatenated_text,\n",
    "                target_lang: record.polish_annotation.text\n",
    "            }\n",
    "        }\n",
    "\n",
    "hf_dataset = Dataset.from_generator(gen, gen_kwargs=gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d251a44f4a245a080b718fc1a5497c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = hf_dataset.class_encode_column(\"task_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['task_label', 'translation'],\n",
       "    num_rows: 39623\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['task_label', 'translation'],\n",
       "        num_rows: 31698\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['task_label', 'translation'],\n",
       "        num_rows: 7925\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = hf_dataset.train_test_split(test_size=0.2, stratify_by_column=\"task_label\")\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0f63facfee426aa43f15e8a62071ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2434762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[\"test\"].to_json(\"hf_dataset_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"allegro/plt5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41d4c8e82244acdb9710997894203bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583cd9b7bd3c4e9f85aeb384a630eb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7925 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PREFIX = \"translate Gloss to Polish: \"\n",
    "\n",
    "prepro_fn_kwargs = {\"source_lang\": SOURCE_LANG, \"target_lang\": TARGET_LANG, \"prefix\": PREFIX}\n",
    "\n",
    "def preprocess_function(examples, source_lang, target_lang, prefix):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_hf_dataset = hf_dataset.map(preprocess_function, batched=True, fn_kwargs=prepro_fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  279,  4067,   358,  3032,   313,  3060,  8135,   485, 25666,     1]])\n",
      "tensor([[    0, 49999,     1]])\n",
      "['規']\n"
     ]
    }
   ],
   "source": [
    "PROMT = \"nie wiem co robię powinno działać bez odbioru\"\n",
    "\n",
    "inputs = tokenizer(PROMT, return_tensors=\"pt\").input_ids\n",
    "print(inputs)\n",
    "\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)\n",
    "print(outputs)\n",
    "\n",
    "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mwe\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert \"we\" == \"stop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 based translator training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODELS_DIR / f\"gloss2polish-translator-{CHECKPOINT.replace('/', '-')}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_hf_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_hf_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\"NUM: OSIEMNAŚCIE 1.1 P:3;L:B\", \"Osiemnastego?\"),\n",
    "    (\"NIE*MIEĆ (= %) 1.4 P:B;L:B\", \"Nie bardzo.\"),\n",
    "    (\"WSKAZ: B (JA) NIE*WIEDZIEĆ/NIE*UMIEĆ 1.1 P:B;L:B\", \"Nie wiem.\"),\n",
    "    (\"PODOBNY 5.3 P:B;L:Ø WOŁAĆ 1.2 P:B;L:B (POLICZEK) POMAGAĆ/POMOC 1.5 ® P:B;L:B (MNIE)/ DO SIEBIE\", \"To chyba wołanie o pomoc.\"),\n",
    "    (\"UWAGA 1.2 P:Z;L:Ø KREW 1.1 P:G;L:A ###\", \"Na jego kolanie widać krew.\"),\n",
    "    (\"MUSIEĆ 2.1 P:L;L:Ø SZUKAĆ 2.5 P:V;L:V NAUCZYCIELKA P:E;L:E JĘZYK 1.1 P:Z;L:Ø ANGLIA/ANGIELSKI 1.1 P:B;L:Ø\", \"Musimy szukać nauczyciela języka angielskiego.\"),\n",
    "    (\"WSKAZ: Z WSZYSTKIE KIERUNKI SPAĆ/ZASNĄĆ 2.1 P:LP;L:Ø GŁUCHY 1.1 P:N;L:Ø G: A+B (MŁOTEK/WALIĆ/UDERZAĆ) ROBIĆ 1.1 P:C;L:C WSKAZ: Z (WSZYSTKIE KIERUNKI/STRZELAĆ/JEŹDZIĆ/WŁAŚNIE/TO/W-TYM-ROKU) IDENTYF: (CHARLIE CHAPLIN)+WĄS+KSZTAŁT-C DOBRZE 1.1 P:O;L:O ROBIĆ 1.1 P:C;L:C WSKAZ: Z (WSZYSTKIE KIERUNKI/STRZELAĆ/JEŹDZIĆ/WŁAŚNIE/TO/W-TYM-ROKU)\", \"Tam spał głuchy, nadal uderzali w drzwi.\")\n",
    "]\n",
    "for gloss_pl_concatenated_text, polish_text in examples:\n",
    "    translation_result = translator(PREFIX + gloss_pl_concatenated_text)\n",
    "    print()\n",
    "    pprint({\n",
    "        \"gloss_pl\": gloss_pl_concatenated_text,\n",
    "        \"translation_result\": translation_result,\n",
    "        \"ground_truth\": polish_text,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
