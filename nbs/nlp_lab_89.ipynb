{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocena modeli dystrybucyjnych dla korpusu pełnego i wzorcowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.settings import POLISH_ANNOTATIONS_FPATH, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "EMB_VECTOR_SIZE = 100\n",
    "EMB_WINDOW = 5\n",
    "VOCAB_MIN_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych do klasyfikacji (tekst - numer zadania), korpus wzorcowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>doc_filepath</th>\n",
       "      <th>video_filename</th>\n",
       "      <th>task_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39040</td>\n",
       "      <td>41120</td>\n",
       "      <td>Myślę, że mam inny pomysł, można?</td>\n",
       "      <td>/15/K66BF13-26_15_15_signsNO.eaf</td>\n",
       "      <td>K66BF13-26.mp4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41120</td>\n",
       "      <td>49680</td>\n",
       "      <td>Chyba ten znak mówi, że jak ktoś będzie spacer...</td>\n",
       "      <td>/15/K66BF13-26_15_15_signsNO.eaf</td>\n",
       "      <td>K66BF13-26.mp4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49680</td>\n",
       "      <td>55280</td>\n",
       "      <td>Trzeba przejść łukiem obok leżącego i o tym zn...</td>\n",
       "      <td>/15/K66BF13-26_15_15_signsNO.eaf</td>\n",
       "      <td>K66BF13-26.mp4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61280</td>\n",
       "      <td>66840</td>\n",
       "      <td>Okrągły znak pomaga nam, mówi, że są pasy na u...</td>\n",
       "      <td>/15/K66BF13-26_15_15_signsNO.eaf</td>\n",
       "      <td>K66BF13-26.mp4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66840</td>\n",
       "      <td>73200</td>\n",
       "      <td>Jak ktoś zobaczy, ale zignoruje ten znak, to m...</td>\n",
       "      <td>/15/K66BF13-26_15_15_signsNO.eaf</td>\n",
       "      <td>K66BF13-26.mp4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40350</th>\n",
       "      <td>248960</td>\n",
       "      <td>250320</td>\n",
       "      <td>[uderzanie w coś]</td>\n",
       "      <td>/13/K17BF13-26_13_13_comics.eaf</td>\n",
       "      <td>K17BF13-26.mp4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40351</th>\n",
       "      <td>279560</td>\n",
       "      <td>291400</td>\n",
       "      <td>Kot zobaczył w akwarium rybkę. Podszedł i dał ...</td>\n",
       "      <td>/13/K17BF13-26_13_13_comics.eaf</td>\n",
       "      <td>K17BF13-26.mp4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40352</th>\n",
       "      <td>291400</td>\n",
       "      <td>347120</td>\n",
       "      <td>Zjadłam, zjadłam.</td>\n",
       "      <td>/13/K17BF13-26_13_13_comics.eaf</td>\n",
       "      <td>K17BF13-26.mp4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40353</th>\n",
       "      <td>347120</td>\n",
       "      <td>356440</td>\n",
       "      <td>Zając biegnie, zobaczył wiszące pranie. Wskocz...</td>\n",
       "      <td>/13/K17BF13-26_13_13_comics.eaf</td>\n",
       "      <td>K17BF13-26.mp4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40354</th>\n",
       "      <td>359240</td>\n",
       "      <td>361760</td>\n",
       "      <td>Kombinezon dziecka, tak na siebie założył.</td>\n",
       "      <td>/13/K17BF13-26_13_13_comics.eaf</td>\n",
       "      <td>K17BF13-26.mp4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40355 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        start     end                                               text  \\\n",
       "0       39040   41120                  Myślę, że mam inny pomysł, można?   \n",
       "1       41120   49680  Chyba ten znak mówi, że jak ktoś będzie spacer...   \n",
       "2       49680   55280  Trzeba przejść łukiem obok leżącego i o tym zn...   \n",
       "3       61280   66840  Okrągły znak pomaga nam, mówi, że są pasy na u...   \n",
       "4       66840   73200  Jak ktoś zobaczy, ale zignoruje ten znak, to m...   \n",
       "...       ...     ...                                                ...   \n",
       "40350  248960  250320                                  [uderzanie w coś]   \n",
       "40351  279560  291400  Kot zobaczył w akwarium rybkę. Podszedł i dał ...   \n",
       "40352  291400  347120                                  Zjadłam, zjadłam.   \n",
       "40353  347120  356440  Zając biegnie, zobaczył wiszące pranie. Wskocz...   \n",
       "40354  359240  361760         Kombinezon dziecka, tak na siebie założył.   \n",
       "\n",
       "                           doc_filepath  video_filename  task_label  \n",
       "0      /15/K66BF13-26_15_15_signsNO.eaf  K66BF13-26.mp4          15  \n",
       "1      /15/K66BF13-26_15_15_signsNO.eaf  K66BF13-26.mp4          15  \n",
       "2      /15/K66BF13-26_15_15_signsNO.eaf  K66BF13-26.mp4          15  \n",
       "3      /15/K66BF13-26_15_15_signsNO.eaf  K66BF13-26.mp4          15  \n",
       "4      /15/K66BF13-26_15_15_signsNO.eaf  K66BF13-26.mp4          15  \n",
       "...                                 ...             ...         ...  \n",
       "40350   /13/K17BF13-26_13_13_comics.eaf  K17BF13-26.mp4          13  \n",
       "40351   /13/K17BF13-26_13_13_comics.eaf  K17BF13-26.mp4          13  \n",
       "40352   /13/K17BF13-26_13_13_comics.eaf  K17BF13-26.mp4          13  \n",
       "40353   /13/K17BF13-26_13_13_comics.eaf  K17BF13-26.mp4          13  \n",
       "40354   /13/K17BF13-26_13_13_comics.eaf  K17BF13-26.mp4          13  \n",
       "\n",
       "[40355 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korpus_wzorcowy = pd.read_json(POLISH_ANNOTATIONS_FPATH, lines=True)\n",
    "korpus_wzorcowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15', '24', '7', '17', '8', '13']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_labels = korpus_wzorcowy[\"task_label\"].astype(str).unique().tolist()\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korpus_wzorcowy[\"text\"].isna().sum(), korpus_wzorcowy[\"task_label\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ktoś biega bez świadomości i może spowodować wypadek a znak nam pomaga przypomina żeby uważać'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import token\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def preprocess(text, stopwords):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text, language=\"polish\")\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "    if not any(tokens):\n",
    "        return np.nan\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "with open(DATA_DIR / \"polish.stopwords.txt\", \"r\") as f:\n",
    "    stop_words = set(f.readlines())\n",
    "\n",
    "korpus_wzorcowy_preprocessed = korpus_wzorcowy.copy()\n",
    "korpus_wzorcowy_preprocessed[\"text\"] = korpus_wzorcowy_preprocessed[\"text\"].apply(preprocess, args=(stop_words,))\n",
    "\n",
    "korpus_wzorcowy_preprocessed[\"text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start             0\n",
       "end               0\n",
       "text              2\n",
       "doc_filepath      0\n",
       "video_filename    0\n",
       "task_label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korpus_wzorcowy_preprocessed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40353, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data_preprocessed = korpus_wzorcowy_preprocessed.dropna()\n",
    "pl_data_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wzorcowy_X_train, wzorcowy_X_test, wzorcowy_y_train, wzorcowy_y_test = train_test_split(\n",
    "    pl_data_preprocessed['text'],\n",
    "    pl_data_preprocessed['task_label'],\n",
    "    test_size=0.2,\n",
    "    stratify=pl_data_preprocessed['task_label'],\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32282,), (8071,), (32282,), (8071,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wzorcowy_X_train.shape, wzorcowy_X_test.shape, wzorcowy_y_train.shape, wzorcowy_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wzorcowy_train_tokens = wzorcowy_X_train.str.split().explode().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "wzorcowy_skipgram = Word2Vec(wzorcowy_train_tokens, sg=1, vector_size=EMB_VECTOR_SIZE, window=EMB_WINDOW, min_count=VOCAB_MIN_COUNT, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wzorcowy_cbow = Word2Vec(wzorcowy_train_tokens, sg=0, vector_size=EMB_VECTOR_SIZE, window=EMB_WINDOW, min_count=VOCAB_MIN_COUNT, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence, w2v_model):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)\n",
    "\n",
    "wzorcowy_X_train_skipgram = np.array([vectorize(sentence, w2v_model=wzorcowy_skipgram) for sentence in wzorcowy_X_train])\n",
    "wzorcowy_X_test_skipgram = np.array([vectorize(sentence, w2v_model=wzorcowy_skipgram) for sentence in wzorcowy_X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wzorcowy_X_train_cbow = np.array([vectorize(sentence, w2v_model=wzorcowy_cbow) for sentence in wzorcowy_X_train])\n",
    "wzorcowy_X_test_cbow = np.array([vectorize(sentence, w2v_model=wzorcowy_cbow) for sentence in wzorcowy_X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# wzorcowy_skipgram_clf = LogisticRegression()\n",
    "wzorcowy_skipgram_clf = DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "wzorcowy_skipgram_clf.fit(wzorcowy_X_train_skipgram, wzorcowy_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wzorcowy_cbow_clf = LogisticRegression()\n",
    "wzorcowy_cbow_clf = DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "wzorcowy_cbow_clf.fit(wzorcowy_X_train_cbow, wzorcowy_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          15     0.6519    0.0650    0.1183      1814\n",
      "          24     0.3231    0.0184    0.0348      1143\n",
      "           7     0.0000    0.0000    0.0000       997\n",
      "          17     0.3252    0.8510    0.4706      2410\n",
      "           8     0.3015    0.3491    0.3236      1266\n",
      "          13     0.4808    0.0567    0.1014       441\n",
      "\n",
      "    accuracy                         0.3292      8071\n",
      "   macro avg     0.3471    0.2234    0.1748      8071\n",
      "weighted avg     0.3629    0.3292    0.2283      8071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_clf(clf, X_test, y_test, target_names=None):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return classification_report(y_test, y_pred, output_dict=False, target_names=target_names, zero_division=0, digits=4)\n",
    "\n",
    "skipgram_clf_report = evaluate_clf(wzorcowy_skipgram_clf, wzorcowy_X_test_skipgram, wzorcowy_y_test, target_names=target_labels)\n",
    "print(skipgram_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          15     0.6667    0.0650    0.1185      1814\n",
      "          24     0.3088    0.0184    0.0347      1143\n",
      "           7     0.0000    0.0000    0.0000       997\n",
      "          17     0.3246    0.8506    0.4699      2410\n",
      "           8     0.3003    0.3476    0.3222      1266\n",
      "          13     0.5000    0.0522    0.0945       441\n",
      "\n",
      "    accuracy                         0.3286      8071\n",
      "   macro avg     0.3501    0.2223    0.1733      8071\n",
      "weighted avg     0.3649    0.3286    0.2276      8071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_clf_report = evaluate_clf(wzorcowy_cbow_clf, wzorcowy_X_test_cbow, wzorcowy_y_test, target_names=target_labels)\n",
    "print(cbow_clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
