{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from random import choices\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from jsonlines import jsonlines\n",
    "from typing import Dict, List, Any\n",
    "from matplotlib import pyplot as plt\n",
    "import evaluate\n",
    "from datetime import datetime\n",
    "\n",
    "from src.settings import PREPROCESSED_DIR, MODELS_DIR, LOGS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # return torch.device('cpu')\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
    "        scaled = scaled.permute(1, 0, 2, 3)\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = (torch.arange(self.max_sequence_length)\n",
    "                          .reshape(self.max_sequence_length, 1))\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "\n",
    "class SentenceEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_sequence_length, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x): # batched tokens ids\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        batch_size, sequence_length, d_model = x.size()\n",
    "        qkv = self.qkv_layer(x)\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        y = (inputs - mean) / std\n",
    "        out = self.gamma * y + self.beta\n",
    "        return out\n",
    "\n",
    "  \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        residual_x = x.clone()\n",
    "        x = self.attention(x, mask=self_attention_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual_x)\n",
    "        residual_x = x.clone()\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual_x)\n",
    "        return x\n",
    "    \n",
    "class SequentialEncoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, self_attention_mask  = inputs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "class FrameLandmarksEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_frames, d_model, n_landmarks=99):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_frames\n",
    "        self.linear = nn.Linear(n_landmarks, d_model)\n",
    "        self.position_encoder = PositionalEncoding(d_model, self.max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):  # seq of frames (landmarks), batched\n",
    "        # in: (batch_size, n_frames, 99)\n",
    "        # x = x[:, :self.max_sequence_length, :]\n",
    "        # x = F.pad(x, (0, 0, 0, self.max_sequence_length - x.size(1)), value=-1)\n",
    "        x = self.linear(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        # out: (batch_size, max_sequence_length, d_model)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.frames_seq_embedding = FrameLandmarksEmbedding(max_sequence_length, d_model)\n",
    "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
    "                                      for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        # x = self.sentence_embedding(x, start_token, end_token)\n",
    "        x = self.frames_seq_embedding(x)\n",
    "        x = self.layers(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, y, mask):\n",
    "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
    "        kv = self.kv_layer(x)\n",
    "        q = self.q_layer(y)\n",
    "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
    "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        kv = kv.permute(0, 2, 1, 3)\n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        k, v = kv.chunk(2, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        _y = y.clone()\n",
    "        y = self.self_attention(y, mask=self_attention_mask)\n",
    "        y = self.dropout1(y)\n",
    "        y = self.layer_norm1(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer_norm2(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.ffn(y)\n",
    "        y = self.dropout3(y)\n",
    "        y = self.layer_norm3(y + _y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SequentialDecoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length,\n",
    "                 vocab_size,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, vocab_size)\n",
    "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        y = self.sentence_embedding(y)\n",
    "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "        d_model, \n",
    "        ffn_hidden, \n",
    "        num_heads, \n",
    "        drop_prob, \n",
    "        num_layers,\n",
    "        max_sequence_length, \n",
    "        vocab_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length)\n",
    "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size)\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, \n",
    "                x, \n",
    "                y, \n",
    "                encoder_self_attention_mask=None, \n",
    "                decoder_self_attention_mask=None, \n",
    "                decoder_cross_attention_mask=None,\n",
    "    ):\n",
    "        x = self.encoder(x, encoder_self_attention_mask)\n",
    "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HEADS = 8\n",
    "DROP_PROB = 0.1\n",
    "NUM_LAYERS = 5\n",
    "D_MODEL = 512\n",
    "FFN_HIDDEN = 2048\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50  # max in frames = max out tokens\n",
    "N_LANDMARKS = 99\n",
    "VOCAB_SIZE = 50_000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SAMPLE_FRAC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, records: List[Dict[str, Any]], max_input_lenght, max_output_length):\n",
    "        self.records = records\n",
    "        self.max_input_lenght = max_input_lenght\n",
    "        self.max_output_length = max_output_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
    "        out_polish_token_ids = torch.tensor(self.records[index][\"PolishAnnotationTokenIds\"], dtype=torch.int32)\n",
    "        if len(out_polish_token_ids) > 66:\n",
    "            # FIXME: this is a hack to make it work with the model; only one clip is affected\n",
    "            print(\"Warning: PolishAnnotationTokenIds is longer than 66\")\n",
    "            out_polish_token_ids = out_polish_token_ids[:66]\n",
    "\n",
    "        out_polish_token_ids = out_polish_token_ids[:self.max_output_length]\n",
    "\n",
    "        # (seq_len x 33 x 3) -> (seq_len x 99)\n",
    "        frame_seq_landmarks = torch.tensor(self.records[index][\"FramesLandmarksCoords\"], dtype=torch.float32).view(-1, 99)\n",
    "        every_nth_frame_seq_landmarks = frame_seq_landmarks[::4]  # get every 4th frame\n",
    "        seq_pad_len = self.max_input_lenght - every_nth_frame_seq_landmarks.size(0)\n",
    "        padded_frame_seq_landmarks = F.pad(every_nth_frame_seq_landmarks, (0, 0, 0, seq_pad_len), value=0)  # 200x99\n",
    "        # prepro_landmarks_seq = self.preprocess_landmarks_seq(frame_seq_landmarks)\n",
    "\n",
    "        return {\n",
    "            \"in_landmarks\": padded_frame_seq_landmarks,\n",
    "            \"out_polish_token_ids\": out_polish_token_ids,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m         raw_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m((rec \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m reader \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m], p\u001b[38;5;241m=\u001b[39m[SAMPLE_FRAC, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m SAMPLE_FRAC])))  \u001b[38;5;66;03m# iterable approach for random sample\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m         raw_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_records, val_records \u001b[38;5;241m=\u001b[39m train_test_split(raw_records, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jsonlines/jsonlines.py:434\u001b[0m, in \u001b[0;36mReader.iter\u001b[0;34m(self, type, allow_none, skip_empty, skip_invalid)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_none\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_empty\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidLineError:\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_invalid:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jsonlines/jsonlines.py:307\u001b[0m, in \u001b[0;36mReader.read\u001b[0;34m(self, type, allow_none, skip_empty)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid type specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     lineno, line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_line_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m skip_empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mrstrip():\n\u001b[1;32m    309\u001b[0m         lineno, line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line_iter)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with jsonlines.open(PREPROCESSED_DIR / \"clips_dataset_wth_herbert_token_ids.jsonl\") as reader:\n",
    "    # total_records: 19_503\n",
    "    if SAMPLE_FRAC < 1:\n",
    "        raw_records = list((rec for rec in reader if np.random.choice([True, False], p=[SAMPLE_FRAC, 1 - SAMPLE_FRAC])))  # iterable approach for random sample\n",
    "    else:\n",
    "        raw_records = list(reader)\n",
    "\n",
    "train_records, val_records = train_test_split(raw_records, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ClipsDataset(train_records, max_input_lenght=MAX_SEQUENCE_LENGTH, max_output_length=MAX_SEQUENCE_LENGTH)\n",
    "val_ds = ClipsDataset(val_records, max_input_lenght=MAX_SEQUENCE_LENGTH, max_output_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# del train_records, val_records, raw_records\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in train_ds:\n",
    "    print(record[\"in_landmarks\"].shape)  # n_frames x n_landmarks*3\n",
    "    print(record[\"out_polish_token_ids\"].shape)  # padded n_tokens\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in train_dl:\n",
    "    print(record[\"in_landmarks\"].shape)  # n_frames x n_landmarks*3\n",
    "    print(record[\"out_polish_token_ids\"].shape)  # padded n_tokens\n",
    "    print(record[\"out_polish_token_ids\"][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(seq_landmarks_batch, token_ids_batch):\n",
    "    num_sentences = len(seq_landmarks_batch)\n",
    "    look_ahead_mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      seq_landmarks_len = len(seq_landmarks_batch[idx])\n",
    "      seq_token_ids_len = len(token_ids_batch[idx])\n",
    "      seq_landmarks_pad_mask_ids = np.arange(seq_landmarks_len + 1, MAX_SEQUENCE_LENGTH)\n",
    "      seq_token_ids_pad_mask_ids = np.arange(seq_token_ids_len + 1, MAX_SEQUENCE_LENGTH)\n",
    "      encoder_padding_mask[idx, :, seq_landmarks_pad_mask_ids] = True\n",
    "      encoder_padding_mask[idx, seq_landmarks_pad_mask_ids, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, seq_token_ids_pad_mask_ids] = True\n",
    "      decoder_padding_mask_self_attention[idx, seq_token_ids_pad_mask_ids, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, seq_landmarks_pad_mask_ids] = True\n",
    "      decoder_padding_mask_cross_attention[idx, seq_token_ids_pad_mask_ids, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, model, tokenizer, criterion, optim):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(x, y)\n",
    "\n",
    "    prediction = model(x, y, encoder_self_attention_mask.to(DEVICE),  decoder_self_attention_mask.to(DEVICE), decoder_cross_attention_mask.to(DEVICE))\n",
    "\n",
    "    criterion_input = prediction.view(-1, VOCAB_SIZE)\n",
    "    criterion_target = y.view(-1).long()\n",
    "    loss = criterion(criterion_input, criterion_target)\n",
    "\n",
    "    valid_indicies = torch.where(criterion_target.view(-1) == tokenizer.pad_token_id, False, True)\n",
    "    loss = loss.sum() / valid_indicies.sum()\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_step(x, y, model, tokenizer, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(x, y)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(x, y, encoder_self_attention_mask.to(DEVICE),  decoder_self_attention_mask.to(DEVICE), decoder_cross_attention_mask.to(DEVICE))\n",
    "\n",
    "        criterion_input = prediction.view(-1, VOCAB_SIZE)\n",
    "        criterion_target = y.view(-1).long()\n",
    "        loss = criterion(criterion_input, criterion_target)\n",
    "\n",
    "        valid_indicies = torch.where(criterion_target.view(-1) == tokenizer.pad_token_id, False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "\n",
    "    return prediction, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ").to(DEVICE)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer.pad_token_id = 1\n",
    "tokenizer.bos_token_id = 0\n",
    "tokenizer.eos_token_id = 2\n",
    "\n",
    "print(f\"{tokenizer.vocab_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_model = evaluate.load(\"meteor\")\n",
    "bertscore_model = evaluate.load(\"bertscore\")\n",
    "ter_model = evaluate.load(\"ter\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction=\"none\")\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_batches = len(train_dl)\n",
    "n_val_batches = len(val_dl)\n",
    "\n",
    "metrics_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\" Epoch {epoch} \".center(80, \"-\"))\n",
    "    \n",
    "    epoch_metrics = {\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"TrainLoss\": 0,\n",
    "        \"ValLoss\": 0,\n",
    "        \"ValMETEOR\": 0,\n",
    "        \"ValBERTScoreAvgF1\": 0,\n",
    "        \"ValBERTScoreAvgPrecision\": 0,\n",
    "        \"ValBERTScoreAvgRecall\": 0,\n",
    "        \"ValTER\": 0,\n",
    "        \"ValBLEU\": 0,\n",
    "    }\n",
    "\n",
    "    # Epoch Training\n",
    "    for batch_num, (train_batch, val_batch) in enumerate(zip(train_dl, val_dl)):\n",
    "        x_train, y_train = train_batch[\"in_landmarks\"].to(DEVICE), train_batch[\"out_polish_token_ids\"].to(DEVICE)\n",
    "        train_loss = train_step(x_train, y_train, transformer, tokenizer, criterion, optim)\n",
    "\n",
    "        epoch_metrics[\"TrainLoss\"] += train_loss / n_train_batches\n",
    "\n",
    "    # Epoch Validation\n",
    "    for batch_num, val_batch in enumerate(val_dl):\n",
    "        x_val, y_val = val_batch[\"in_landmarks\"].to(DEVICE), val_batch[\"out_polish_token_ids\"].to(DEVICE)\n",
    "        val_pred, val_loss = eval_step(x_val, y_val, transformer, tokenizer, criterion)\n",
    "        \n",
    "        y_batch_decoded = tokenizer.batch_decode(y_val, skip_special_tokens=True)\n",
    "        val_ids_predictions = torch.argmax(val_pred, dim=-1)\n",
    "        val_pred_decoded = tokenizer.batch_decode(val_ids_predictions, skip_special_tokens=True)\n",
    "\n",
    "        meteor_score = meteor_model.compute(\n",
    "            predictions=val_pred_decoded,\n",
    "            references=y_batch_decoded,\n",
    "        )\n",
    "        bert_score = bertscore_model.compute(\n",
    "            predictions=val_pred_decoded,\n",
    "            references=y_batch_decoded,\n",
    "            lang=\"pl\"\n",
    "        )\n",
    "        ter_score = ter_model.compute(\n",
    "            predictions=val_pred_decoded,\n",
    "            references=y_batch_decoded,\n",
    "        )\n",
    "        bleu_score = sacrebleu.compute(\n",
    "            predictions=val_pred_decoded,\n",
    "            references=y_batch_decoded,\n",
    "        )\n",
    "\n",
    "        epoch_metrics[\"ValLoss\"] += val_loss / n_val_batches\n",
    "        epoch_metrics[\"ValMETEOR\"] += meteor_score[\"meteor\"] / n_val_batches\n",
    "        epoch_metrics[\"ValBERTScoreAvgF1\"] += np.mean(bert_score[\"f1\"]) / n_val_batches\n",
    "        epoch_metrics[\"ValBERTScoreAvgPrecision\"] += np.mean(bert_score[\"precision\"]) / n_val_batches\n",
    "        epoch_metrics[\"ValBERTScoreAvgRecall\"] += np.mean(bert_score[\"recall\"]) / n_val_batches\n",
    "        epoch_metrics[\"ValTER\"] += ter_score[\"score\"] / n_val_batches\n",
    "        epoch_metrics[\"ValBLEU\"] += bleu_score[\"score\"] / n_val_batches\n",
    "\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num}  |  TrainLoss: {train_loss:.4f} ValLoss: {val_loss:.4f}\")\n",
    "            print((\n",
    "                f\"ValMETEOR: {meteor_score['meteor']:.4f}\"\n",
    "                f\" ValBERTScoreAvgF1: {np.mean(bert_score['f1']):.4f}\"\n",
    "                f\" ValBERTScoreAvgPrecision: {np.mean(bert_score['precision']):.4f}\"\n",
    "                f\" ValBERTScoreAvgRecall: {np.mean(bert_score['recall']):.4f}\"\n",
    "                f\" ValTER: {ter_score['score']:.4f}\"\n",
    "                f\" ValBLEU: {bleu_score['score']:.4f}\"\n",
    "            ))\n",
    "            for i in choices(range(BATCH_SIZE), k=3):\n",
    "                print(f\"Polish Annotation: {y_batch_decoded[i]}\")\n",
    "                print(f\"Prediction (Val): {val_pred_decoded[i]}\")\n",
    "                print()\n",
    "\n",
    "    metrics_history.append(epoch_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_records(metrics_history)\n",
    "metrics_df.to_csv(LOGS_DIR / f\"transformer_train_eval_metrics__{datetime.now().strftime('%Y%m%d_%H%M%Sf%f')}.csv\", index=False)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"TrainLoss\", label=\"Training\")\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"ValLoss\", label=\"Validation\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Set the colors for the lines\n",
    "color1 = sns.color_palette(\"Paired\")[1]\n",
    "color2 = sns.color_palette(\"Paired\")[3]\n",
    "color3 = sns.color_palette(\"Paired\")[5]\n",
    "\n",
    "# Plot the first two lines with the primary y-axis\n",
    "sns.lineplot(\n",
    "    data=metrics_df,\n",
    "    x=\"Epoch\",\n",
    "    y=\"ValMETEOR\",\n",
    "    ax=ax1,\n",
    "    label=\"METEOR\",\n",
    "    color=color1,\n",
    "    legend=False,\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=metrics_df,\n",
    "    x=\"Epoch\",\n",
    "    y=\"ValBERTScoreAvgF1\",\n",
    "    ax=ax1,\n",
    "    label=\"BERTScore Avg F1\",\n",
    "    color=color2,\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "# Create a second y-axis for the third line\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=metrics_df,\n",
    "    x=\"Epoch\",\n",
    "    y=\"ValTER\",\n",
    "    ax=ax2,\n",
    "    label=\"TER\",\n",
    "    color=color3,\n",
    ")\n",
    "\n",
    "# Set the labels for the y-axes\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('Value')\n",
    "\n",
    "# Set the label for the x-axis\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax2.set_ylabel(\"\")\n",
    "\n",
    "# Add a legend for all lines\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='lower right')\n",
    "\n",
    "plt.title('Validation\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), MODELS_DIR / \"transformer_v1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in transformer.parameters())\n",
    "trainable_params = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"{total_params=:,}\")\n",
    "print(f\"{trainable_params=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, N_LANDMARKS) ).to(DEVICE) # includes positional encoding\n",
    "out = encoder(x, self_attention_mask=None)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, D_MODEL) ).to(DEVICE)  # seq of frames (landmarks), batched; positional encoded\n",
    "y = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, MAX_SEQUENCE_LENGTH) ).to(DEVICE)  # batched tokens ids; positional encoded\n",
    "\n",
    "mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , float('-inf')).to(DEVICE)\n",
    "mask = torch.triu(mask, diagonal=1).to(DEVICE)\n",
    "\n",
    "decoder = Decoder(D_MODEL, FFN_HIDDEN, NUM_HEADS, DROP_PROB, NUM_LAYERS, MAX_SEQUENCE_LENGTH, VOCAB_SIZE).to(DEVICE)\n",
    "\n",
    "out = decoder(x, y, mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, N_LANDMARKS) ).to(get_device())\n",
    "y = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, MAX_SEQUENCE_LENGTH) ).to(get_device())\n",
    "\n",
    "result = transformer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = \"allegro/herbert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n",
    "tokenizer.pad_token_id = 1\n",
    "tokenizer.bos_token_id = 0\n",
    "tokenizer.eos_token_id = 2\n",
    "\n",
    "tokenizer.decode(2), tokenizer.eos_token_id, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from pprint import pprint\n",
    "\n",
    "meteor_model = evaluate.load(\"meteor\")\n",
    "bertscore_model = evaluate.load(\"bertscore\")\n",
    "ter_model = evaluate.load(\"ter\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "for batch in val_dl:\n",
    "    y_val = batch[\"out_polish_token_ids\"].to(DEVICE)\n",
    "    decoded_y_val = tokenizer.batch_decode(y_val, skip_special_tokens=True)\n",
    "    meteor_score = meteor_model.compute(\n",
    "        predictions=decoded_y_val,\n",
    "        references=decoded_y_val,\n",
    "    )\n",
    "    bert_score = bertscore_model.compute(\n",
    "        predictions=decoded_y_val,\n",
    "        references=decoded_y_val,\n",
    "        lang=\"pl\"\n",
    "    )\n",
    "    ter_score = ter_model.compute(\n",
    "        predictions=decoded_y_val,\n",
    "        references=decoded_y_val,\n",
    "    )\n",
    "    blue_score = sacrebleu.compute(\n",
    "        predictions=decoded_y_val,\n",
    "        references=decoded_y_val,\n",
    "    )\n",
    "    pprint(f\"{meteor_score=}\")\n",
    "    pprint(f\"{bert_score=}\")\n",
    "    pprint(f\"{ter_score=}\")\n",
    "    pprint(f\"{blue_score=}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
