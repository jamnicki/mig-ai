{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from random import choices\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from jsonlines import jsonlines\n",
    "from typing import Dict, List, Any\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.settings import PREPROCESSED_DIR, MODELS_DIR, LOGS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # return torch.device('cpu')\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
    "        scaled = scaled.permute(1, 0, 2, 3)\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = (torch.arange(self.max_sequence_length)\n",
    "                          .reshape(self.max_sequence_length, 1))\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "\n",
    "class SentenceEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_sequence_length, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x): # batched tokens ids\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        batch_size, sequence_length, d_model = x.size()\n",
    "        qkv = self.qkv_layer(x)\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        y = (inputs - mean) / std\n",
    "        out = self.gamma * y + self.beta\n",
    "        return out\n",
    "\n",
    "  \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        residual_x = x.clone()\n",
    "        x = self.attention(x, mask=self_attention_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual_x)\n",
    "        residual_x = x.clone()\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual_x)\n",
    "        return x\n",
    "    \n",
    "class SequentialEncoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, self_attention_mask  = inputs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "class FrameLandmarksEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_frames, d_model, n_landmarks=99):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_frames\n",
    "        self.linear = nn.Linear(n_landmarks, d_model)\n",
    "        self.position_encoder = PositionalEncoding(d_model, self.max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):  # seq of frames (landmarks), batched\n",
    "        # in: (batch_size, n_frames, 99)\n",
    "        # x = x[:, :self.max_sequence_length, :]\n",
    "        # x = F.pad(x, (0, 0, 0, self.max_sequence_length - x.size(1)), value=-1)\n",
    "        x = self.linear(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        # out: (batch_size, max_sequence_length, d_model)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.frames_seq_embedding = FrameLandmarksEmbedding(max_sequence_length, d_model)\n",
    "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
    "                                      for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        # x = self.sentence_embedding(x, start_token, end_token)\n",
    "        x = self.frames_seq_embedding(x)\n",
    "        x = self.layers(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, y, mask):\n",
    "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
    "        kv = self.kv_layer(x)\n",
    "        q = self.q_layer(y)\n",
    "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
    "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        kv = kv.permute(0, 2, 1, 3)\n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        k, v = kv.chunk(2, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        _y = y.clone()\n",
    "        y = self.self_attention(y, mask=self_attention_mask)\n",
    "        y = self.dropout1(y)\n",
    "        y = self.layer_norm1(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer_norm2(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.ffn(y)\n",
    "        y = self.dropout3(y)\n",
    "        y = self.layer_norm3(y + _y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SequentialDecoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length,\n",
    "                 vocab_size,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, vocab_size)\n",
    "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        y = self.sentence_embedding(y)\n",
    "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "        d_model, \n",
    "        ffn_hidden, \n",
    "        num_heads, \n",
    "        drop_prob, \n",
    "        num_layers,\n",
    "        max_sequence_length, \n",
    "        vocab_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length)\n",
    "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size)\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, \n",
    "                x, \n",
    "                y, \n",
    "                encoder_self_attention_mask=None, \n",
    "                decoder_self_attention_mask=None, \n",
    "                decoder_cross_attention_mask=None,\n",
    "    ):\n",
    "        x = self.encoder(x, encoder_self_attention_mask)\n",
    "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HEADS = 8\n",
    "DROP_PROB = 0.1\n",
    "NUM_LAYERS = 5\n",
    "D_MODEL = 512\n",
    "FFN_HIDDEN = 2048\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50  # max in frames = max out tokens\n",
    "N_LANDMARKS = 99\n",
    "VOCAB_SIZE = 50_000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SAMPLE_FRAC = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, records: List[Dict[str, Any]], max_input_lenght, max_output_length):\n",
    "        self.records = records\n",
    "        self.max_input_lenght = max_input_lenght\n",
    "        self.max_output_length = max_output_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
    "        out_polish_token_ids = torch.tensor(self.records[index][\"PolishAnnotationTokenIds\"], dtype=torch.int32)\n",
    "        if len(out_polish_token_ids) > 66:\n",
    "            # FIXME: this is a hack to make it work with the model; only one clip is affected\n",
    "            print(\"Warning: PolishAnnotationTokenIds is longer than 66\")\n",
    "            out_polish_token_ids = out_polish_token_ids[:66]\n",
    "\n",
    "        out_polish_token_ids = out_polish_token_ids[:self.max_output_length]\n",
    "\n",
    "        # (seq_len x 33 x 3) -> (seq_len x 99)\n",
    "        frame_seq_landmarks = torch.tensor(self.records[index][\"FramesLandmarksCoords\"], dtype=torch.float32).view(-1, 99)\n",
    "        every_nth_frame_seq_landmarks = frame_seq_landmarks[::4]  # get every 4th frame\n",
    "        seq_pad_len = self.max_input_lenght - every_nth_frame_seq_landmarks.size(0)\n",
    "        padded_frame_seq_landmarks = F.pad(every_nth_frame_seq_landmarks, (0, 0, 0, seq_pad_len), value=0)  # 200x99\n",
    "        # prepro_landmarks_seq = self.preprocess_landmarks_seq(frame_seq_landmarks)\n",
    "\n",
    "        return {\n",
    "            \"in_landmarks\": padded_frame_seq_landmarks,\n",
    "            \"out_polish_token_ids\": out_polish_token_ids,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(PREPROCESSED_DIR / \"clips_dataset_wth_herbert_token_ids.jsonl\") as reader:\n",
    "    # total_records: 19_503\n",
    "    if SAMPLE_FRAC < 1:\n",
    "        raw_records = list((rec for rec in reader if np.random.choice([True, False], p=[SAMPLE_FRAC, 1 - SAMPLE_FRAC])))  # iterable approach for random sample\n",
    "    else:\n",
    "        raw_records = list(reader)\n",
    "\n",
    "train_records, val_records = train_test_split(raw_records, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4677, 1170)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ClipsDataset(train_records, max_input_lenght=MAX_SEQUENCE_LENGTH, max_output_length=MAX_SEQUENCE_LENGTH)\n",
    "val_ds = ClipsDataset(val_records, max_input_lenght=MAX_SEQUENCE_LENGTH, max_output_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# del train_records, val_records, raw_records\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 99])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for record in train_ds:\n",
    "    print(record[\"in_landmarks\"].shape)  # n_frames x n_landmarks*3\n",
    "    print(record[\"out_polish_token_ids\"].shape)  # padded n_tokens\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 99])\n",
      "torch.Size([32, 50])\n",
      "tensor([    0, 49098,  4320,  1019,  3537,  1899,     2,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for record in train_dl:\n",
    "    print(record[\"in_landmarks\"].shape)  # n_frames x n_landmarks*3\n",
    "    print(record[\"out_polish_token_ids\"].shape)  # padded n_tokens\n",
    "    print(record[\"out_polish_token_ids\"][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(seq_landmarks_batch, token_ids_batch):\n",
    "    num_sentences = len(seq_landmarks_batch)\n",
    "    look_ahead_mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      seq_landmarks_len = len(seq_landmarks_batch[idx])\n",
    "      seq_token_ids_len = len(token_ids_batch[idx])\n",
    "      seq_landmarks_pad_mask_ids = np.arange(seq_landmarks_len + 1, MAX_SEQUENCE_LENGTH)\n",
    "      seq_token_ids_pad_mask_ids = np.arange(seq_token_ids_len + 1, MAX_SEQUENCE_LENGTH)\n",
    "      encoder_padding_mask[idx, :, seq_landmarks_pad_mask_ids] = True\n",
    "      encoder_padding_mask[idx, seq_landmarks_pad_mask_ids, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, seq_token_ids_pad_mask_ids] = True\n",
    "      decoder_padding_mask_self_attention[idx, seq_token_ids_pad_mask_ids, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, seq_landmarks_pad_mask_ids] = True\n",
    "      decoder_padding_mask_cross_attention[idx, seq_token_ids_pad_mask_ids, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, model, tokenizer, criterion, optim):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(x, y)\n",
    "\n",
    "    prediction = model(x, y, encoder_self_attention_mask.to(DEVICE),  decoder_self_attention_mask.to(DEVICE), decoder_cross_attention_mask.to(DEVICE))\n",
    "\n",
    "    criterion_input = prediction.view(-1, VOCAB_SIZE)\n",
    "    criterion_target = y.view(-1).long()\n",
    "    loss = criterion(criterion_input, criterion_target)\n",
    "\n",
    "    valid_indicies = torch.where(criterion_target.view(-1) == tokenizer.pad_token_id, False, True)\n",
    "    loss = loss.sum() / valid_indicies.sum()\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_step(x, y, model, tokenizer, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(x, y)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(x, y, encoder_self_attention_mask.to(DEVICE),  decoder_self_attention_mask.to(DEVICE), decoder_cross_attention_mask.to(DEVICE))\n",
    "\n",
    "        criterion_input = prediction.view(-1, VOCAB_SIZE)\n",
    "        criterion_target = y.view(-1).long()\n",
    "        loss = criterion(criterion_input, criterion_target)\n",
    "\n",
    "        valid_indicies = torch.where(criterion_target.view(-1) == tokenizer.pad_token_id, False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "\n",
    "    return prediction, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.vocab_size=50000\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ").to(DEVICE)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer.pad_token_id = 1\n",
    "tokenizer.bos_token_id = 0\n",
    "tokenizer.eos_token_id = 2\n",
    "\n",
    "print(f\"{tokenizer.vocab_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction=\"none\")\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- Epoch 0 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 10.9511 ValLoss: 9.4844\n",
      "Polish Annotation: Bramka.\n",
      "Prediction (Val): ..\n",
      "\n",
      "Polish Annotation: Chłopak sprawdza.\n",
      "Prediction (Val): ....\n",
      "\n",
      "Polish Annotation: W górach jest pełno wycieczek.\n",
      "Prediction (Val): ......\n",
      "\n",
      "----------------------------------- Epoch 1 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 5.2668 ValLoss: 5.3664\n",
      "Polish Annotation: Para nie może się trzymać za ręce.\n",
      "Prediction (Val): nie się..\n",
      "\n",
      "Polish Annotation: Dobrze, poszedł.\n",
      "Prediction (Val): .,.\n",
      "\n",
      "Polish Annotation: Dobrze.\n",
      "Prediction (Val): ..\n",
      "\n",
      "----------------------------------- Epoch 2 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 3.9636 ValLoss: 4.4111\n",
      "Polish Annotation: Bramka.\n",
      "Prediction (Val): .\n",
      "\n",
      "Polish Annotation: Mnie to pasuje!\n",
      "Prediction (Val): . to.\n",
      "\n",
      "Polish Annotation: Chłopak sprawdza.\n",
      "Prediction (Val): Chłopak..\n",
      "\n",
      "----------------------------------- Epoch 3 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 3.0837 ValLoss: 3.8130\n",
      "Polish Annotation: Na przykład w domu jest prysznic, wiesz, taki otwierany na klucz.\n",
      "Prediction (Val): Na przykład w domu jest,., taki mu. na.. się\n",
      "\n",
      "Polish Annotation: Ważne, żeby zapisać ten termin.\n",
      "Prediction (Val): , żeby? ten?. się się się\n",
      "\n",
      "Polish Annotation: Nie wolno, bo spadniesz z siedzenia.\n",
      "Prediction (Val): Nie wolno, bo. wolno z. się się się z z\n",
      "\n",
      "----------------------------------- Epoch 4 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 2.4794 ValLoss: 3.4442\n",
      "Polish Annotation: Dziura.\n",
      "Prediction (Val): Jest w. kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota się się się się się Jak Jak Jak Jak Jak Jak można\n",
      "\n",
      "Polish Annotation: Jest taki stary motor, inny … elektryczny rower, a w drugim jest skuter.\n",
      "Prediction (Val): Jest taki gru,,. …, rower, a w, jest.. kota kota kota kota kota kota się się się się kota kota kota kota gruz z\n",
      "\n",
      "Polish Annotation: Odbiega, bierze wielką kulę do bowlingu.\n",
      "Prediction (Val): Odma,. Po, ę do i szki nie. grukota kota kota kota kota kota kota kota kota kota kota kota kota kota kota się się się się się kota kota kota kota kota z można\n",
      "\n",
      "----------------------------------- Epoch 5 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 2.0519 ValLoss: 3.2183\n",
      "Polish Annotation: Chłopak sprawdza.\n",
      "Prediction (Val): Chłopak.. się się się kota kota kota kota kota kota kota kota kota kota kota kota kota Jak Jak Jak Jak Jak Jak Jak się się Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy można można\n",
      "\n",
      "Polish Annotation: Kot chce się zemścić na rybce.\n",
      "Prediction (Val): Kot chce się gania przez na, Char. się się kota kota kota kota kota kota kota kota kota kota kota kota kota kota Jak Jak się się się się Jak Jak Jak Jak Jak Jak Jak Jak patrzy\n",
      "\n",
      "Polish Annotation: Jest taki stary motor, inny … elektryczny rower, a w drugim jest skuter.\n",
      "Prediction (Val): Jest taki gru,,. …, rower, a w drugim jest.. kota kota kota kota kota kota kota kota się się się Jak Jak Jak Jak Jak Jak z można\n",
      "\n",
      "----------------------------------- Epoch 6 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 1.7063 ValLoss: 3.0573\n",
      "Polish Annotation: Motor jest niebezpieczny.\n",
      "Prediction (Val): . jest.. się się się się kota kota kota się się się się kota kota kota kota kota kota kota kota kota kota kota kota Jak Jak się się się się się się Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy się się\n",
      "\n",
      "Polish Annotation: W górach jest pełno wycieczek.\n",
      "Prediction (Val): W się jest. na. się się kota kota kota się się się kota kota kota kota kota kota kota kota kota kota kota kota kota kota Jak się się się się się się Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy się się się\n",
      "\n",
      "Polish Annotation: Proszę, jak mam zapytać?\n",
      "Prediction (Val): , jak mam,? się kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota kota się się się się się się Jak Jak Jak Jak Jak Jak Jak patrzy patrzy się się\n",
      "\n",
      "----------------------------------- Epoch 7 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 1.4397 ValLoss: 2.9258\n",
      "Polish Annotation: Dobrze, poszedł.\n",
      "Prediction (Val): Dobrze,. lululululuJak Jak Jak Jak Jak kota Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy Jak Jak\n",
      "\n",
      "Polish Annotation: Odbiega, bierze wielką kulę do bowlingu.\n",
      "Prediction (Val): Odbiega, bierze Pokulę do i taki Od. grugrukota kota kota kota kota kota kota kota kota kota Jak Jak Jak Jak Jak Jak Jak się się Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy Jak szył\n",
      "\n",
      "Polish Annotation: Idzie i oddaje temu chłopcu.\n",
      "Prediction (Val): Idzie i.., cu. grugrugrugrugruJak kota kota kota Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak szył szył\n",
      "\n",
      "----------------------------------- Epoch 8 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 1.2457 ValLoss: 2.8293\n",
      "Polish Annotation: Nagle ktoś go wyrzuca i ląduje na kupie złomu, na puszkach po rybach, gwiazdki wirują mu przed oczami.\n",
      "Prediction (Val): Nagle ktoś go wyrzuca i uważać obok na kupie,, na udaje kach po przykład okno,, ki w w mu przed. ododgrusię się się Jak Jak Jak grugrugrugrugruchodzą chodzą grugrukota kota\n",
      "\n",
      "Polish Annotation: Ważne, żeby zapisać ten termin.\n",
      "Prediction (Val): Nie, żeby? ten termin. lulukota kota kota kota kota kota kota kota Jak Jak Jak kota kota kota Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy Jak Jak Jak\n",
      "\n",
      "Polish Annotation: Wyjeżdżam nad morze, nie mogę.\n",
      "Prediction (Val): Wyjeżdżam nad., nie mogę. grugrugrugrukota kota kota kota Jak Jak Jak Jak kota Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak\n",
      "\n",
      "----------------------------------- Epoch 9 ------------------------------------\n",
      "Iteration 0  |  TrainLoss: 1.0532 ValLoss: 2.7385\n",
      "Polish Annotation: Dobrze.\n",
      "Prediction (Val): Dobrze. się się luJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy Jak Jak\n",
      "\n",
      "Polish Annotation: Odbiega, bierze wielką kulę do bowlingu.\n",
      "Prediction (Val): Odbiega, bierze Pokulę do i taki Od. grugrukota kota kota kota kota kota kota kota kota kota Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak chodzą chodzą patrzy Jak Jak Jak\n",
      "\n",
      "Polish Annotation: Od dziesiątej …\n",
      "Prediction (Val): Od dziesiątej … Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy Jak Jak Jak\n",
      "\n",
      "----------------------------------- Epoch 10 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.9204 ValLoss: 2.6625\n",
      "Polish Annotation: Policjant patrzy i zastanawia się,\n",
      "Prediction (Val): Policjant patrzy i zastanawia się, się lululuJak Jak raz raz raz coś Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy szył\n",
      "\n",
      "Polish Annotation: Dobrze.\n",
      "Prediction (Val): Dobrze. lulululululuJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy Jak\n",
      "\n",
      "Polish Annotation: Uwaga, należy oszczędzać.\n",
      "Prediction (Val): Uwaga, należy u. lulululuJak Jak Jak Jak Jak coś coś Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy Jak\n",
      "\n",
      "----------------------------------- Epoch 11 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.7899 ValLoss: 2.5907\n",
      "Polish Annotation: W pewnym momencie, tam na dole z dziury wystaje żaba.\n",
      "Prediction (Val): W pewnym momencie, tam na co z dziury wystaje żaba. kota kota kota raz raz raz raz kota kota kota kota kota Jak Jak Jak Jak Jak Jak się Jak Jak Jak Jak Jak Jak Jak szył chodzą chodzą chodzą chodzą raz raz szył\n",
      "\n",
      "Polish Annotation: Proszę, jak mam zapytać?\n",
      "Prediction (Val): , jak mam wolne? grululuspospospospospospoDziwne Dziwne sposporaz raz MiMiMiJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy raz szył\n",
      "\n",
      "Polish Annotation: Dobrze.\n",
      "Prediction (Val): Dobrze. lulululululuJak Jak Jak Jak raz raz raz raz raz Jak raz raz raz Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy raz szył\n",
      "\n",
      "----------------------------------- Epoch 12 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.6889 ValLoss: 2.5450\n",
      "Polish Annotation: W pewnym momencie, tam na dole z dziury wystaje żaba.\n",
      "Prediction (Val): W pewnym momencie, tam na co z dziury wystaje żaba. się raz raz raz raz raz raz raz kota kota kota Jak Jak Jak Jak Wtorek Wtorek Wtorek się się Jak Jak Jak Jak Jak raz Wtorek chodzą chodzą chodzą raz raz raz raz\n",
      "\n",
      "Polish Annotation: Drugi raz.\n",
      "Prediction (Val): Trójraz. lulululululuraz raz raz raz raz raz raz raz raz raz raz raz raz Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy raz raz\n",
      "\n",
      "Polish Annotation: Okrągły.\n",
      "Prediction (Val): Okrągły. lulululululuJak Jak Jak raz raz raz sposposposporaz raz raz Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy raz raz\n",
      "\n",
      "----------------------------------- Epoch 13 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.5907 ValLoss: 2.5001\n",
      "Polish Annotation: Do …\n",
      "Prediction (Val): Do … Jak Jak Jak Jak spospospoJak Jak Jak raz raz raz spospospoTen Ten Ten Ten MiMiJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy patrzy patrzy patrzy\n",
      "\n",
      "Polish Annotation: Chłopak sprawdza.\n",
      "Prediction (Val): Chłopak Ża. raz raz spospospospoJak Jak raz raz raz raz spospospospoTen Ten Ten Mimasz Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy patrzy patrzy patrzy raz\n",
      "\n",
      "Polish Annotation: Nie wolno, bo spadniesz z siedzenia.\n",
      "Prediction (Val): Nie wolno, bo maniesz z I. luraz raz raz raz raz raz raz raz raz raz raz raz MiMiJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak chodzą patrzy patrzy patrzy patrzy patrzy raz raz\n",
      "\n",
      "----------------------------------- Epoch 14 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.5002 ValLoss: 2.4455\n",
      "Polish Annotation: Mnie to pasuje!\n",
      "Prediction (Val): Mnie to pasuje! Jak Jak Jak Jak Jak Jak Jak raz raz raz raz raz raz raz Ten Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy raz raz raz\n",
      "\n",
      "Polish Annotation: Gdzieś to już wcześniej widziałam.\n",
      "Prediction (Val): Gdzieś to już wcześniej,. uje luspoJak Jak raz raz raz raz raz raz raz raz raz raz raz MiMiJak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak patrzy patrzy patrzy raz raz raz\n",
      "\n",
      "Polish Annotation: Uwaga, należy oszczędzać.\n",
      "Prediction (Val): Uwaga, należy u. lulululuJak Jak raz raz raz raz raz raz raz raz Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak spopatrzy patrzy raz raz raz\n",
      "\n",
      "----------------------------------- Epoch 15 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.4366 ValLoss: 2.4189\n",
      "Polish Annotation: Dziura.\n",
      "Prediction (Val): Dzić. lulululululuTen Ten Ten raz raz raz raz Ten Ten Ten Ten Ten MiMiMiMiTen Ten Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Ten Ten Ten patrzy patrzy patrzy patrzy patrzy patrzy raz\n",
      "\n",
      "Polish Annotation: Mnie to pasuje!\n",
      "Prediction (Val): Mnie to pasuje! uje Ten Ten Ten Ten Ten Ten Ten Ten Ten raz Ten Ten Ten Ten Ten Ten Ten MiMiMiTen Ten Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Ten Ten Ten Ten patrzy patrzy patrzy patrzy patrzy raz raz\n",
      "\n",
      "Polish Annotation: Na przykład w domu jest prysznic, wiesz, taki otwierany na klucz.\n",
      "Prediction (Val): Na przykład w domu jest prysznic, wiesz, taki mu ny na patrzą. coś coś sporaz raz raz raz MiMiMiJak Jak Jak Jak Jak Jak Jak Jak chchJak Jak Jak Jak spospochodzą chodzą chodzą raz raz raz raz\n",
      "\n",
      "----------------------------------- Epoch 16 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.3754 ValLoss: 2.3982\n",
      "Polish Annotation: Nie wolno, bo spadniesz z siedzenia.\n",
      "Prediction (Val): Nie wolno, bo czy niesz z Musi. lugruspospospospospospospospospospospoMimasz masz Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak sposposzył spopatrzy patrzy patrzy patrzy szył szył\n",
      "\n",
      "Polish Annotation: Mnie to pasuje!\n",
      "Prediction (Val): Mnie to pasuje!!!! Ten Ten Ten Ten Ten Ten raz raz spospoTen Ten Ten Ten Ten masz masz masz Ten Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Jak Ten Ten spopatrzy patrzy patrzy patrzy patrzy patrzy szył\n",
      "\n",
      "Polish Annotation: Mnie to pasuje!\n",
      "Prediction (Val): Mnie to pasuje!!!! Ten Ten Ten Ten Ten Ten raz raz spospoTen Ten Ten Ten Ten masz masz masz Ten Ten Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Jak Ten Ten spopatrzy patrzy patrzy patrzy patrzy patrzy szył\n",
      "\n",
      "----------------------------------- Epoch 17 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.3182 ValLoss: 2.3674\n",
      "Polish Annotation: Dobrze.\n",
      "Prediction (Val): Dobrze. lulululuspospospospospospospospospospospospospoTen Ten masz masz masz masz masz Ten Ten Ten Jak Jak Jak Jak Jak Jak Jak Jak Jak spospospospospopatrzy patrzy patrzy szył szył\n",
      "\n",
      "Polish Annotation: Idzie i oddaje temu chłopcu.\n",
      "Prediction (Val): Idzie i oddaje temu chłopcu. luluraz raz raz raz raz raz spospospospospospospomasz masz masz masz Jak Jak dlatego dlatego wszyscy spoJak Jak Jak Jak Jak Jak spospospospospodlatego dlatego raz szył szył\n",
      "\n",
      "Polish Annotation: Bramka.\n",
      "Prediction (Val): Bramka. luluJak spospospospomasz dlatego spospospospomasz spospospoTen Ten masz masz masz masz masz Jak Ten Jak Jak Jak Jak Jak Jak Jak Jak Jak Jak spospospospospopatrzy patrzy patrzy szył szył\n",
      "\n",
      "----------------------------------- Epoch 18 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.2588 ValLoss: 2.3362\n",
      "Polish Annotation: W górach jest pełno wycieczek.\n",
      "Prediction (Val): W Dobra jest pełno na. się coś coś coś raz raz raz raz raz raz raz raz Ten Ten Ten Ten Ten masz masz Ten Ten Ten Ten Ten Ten Ten Ten chchTen Ten Ten Ten Ten Ten Ten patrzy patrzy patrzy raz raz szył\n",
      "\n",
      "Polish Annotation: W górach jest pełno wycieczek.\n",
      "Prediction (Val): W Dobra jest pełno na. się coś coś coś raz raz raz raz raz raz raz raz Ten Ten Ten Ten Ten masz masz Ten Ten Ten Ten Ten Ten Ten Ten chchTen Ten Ten Ten Ten Ten Ten patrzy patrzy patrzy raz raz szył\n",
      "\n",
      "Polish Annotation: Trzeciego lutego.\n",
      "Prediction (Val): taki lutego. lulululuTen Ten Ten Ten Ten Ten Ten raz raz Ten Ten Ten Ten Ten Ten Ten masz masz Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten patrzy patrzy patrzy patrzy raz szył\n",
      "\n",
      "----------------------------------- Epoch 19 -----------------------------------\n",
      "Iteration 0  |  TrainLoss: 0.2215 ValLoss: 2.3226\n",
      "Polish Annotation: Kot chce się zemścić na rybce.\n",
      "Prediction (Val): Kot chce się zemścić na kosz Char. nić raz raz raz raz raz raz raz raz raz raz raz raz masz masz masz masz Ten Ten Ten Ten raz raz Ten chchJak Jak Ten raz raz raz masz masz patrzy raz raz raz raz\n",
      "\n",
      "Polish Annotation: W pewnym momencie, tam na dole z dziury wystaje żaba.\n",
      "Prediction (Val): W pewnym momencie, tam na poz dziury wystaje żaba. raz raz raz raz raz raz raz nić masz masz masz masz Ten Ten Ten Ten Ten Ten Ten chchTen Ten Ten Ten Ten Ten masz masz patrzy raz raz raz raz\n",
      "\n",
      "Polish Annotation: Trafia prosto do kręgielni.\n",
      "Prediction (Val): O, prosto do do od ni. uje Ten Ten Ten Ten Ten raz raz raz Ten Ten Ten Ten Ten Ten masz masz Ten Ten Ten Ten Ten Ten Ten Ten chchTen Ten Ten Ten Ten Ten Ten patrzy patrzy patrzy jego jego raz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\" Epoch {epoch} \".center(80, \"-\"))\n",
    "    for batch_num, (train_batch, val_batch) in enumerate(zip(train_dl, val_dl)):\n",
    "        x_train, y_train = train_batch[\"in_landmarks\"].to(DEVICE), train_batch[\"out_polish_token_ids\"].to(DEVICE)\n",
    "        x_val, y_val = val_batch[\"in_landmarks\"].to(DEVICE), val_batch[\"out_polish_token_ids\"].to(DEVICE)\n",
    "\n",
    "        train_loss = train_step(x_train, y_train, transformer, tokenizer, criterion, optim)\n",
    "        val_pred, val_loss = eval_step(x_val, y_val, transformer, tokenizer, criterion)\n",
    "\n",
    "        metrics_history.append({\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Batch\": batch_num + 1,\n",
    "            \"TrainLoss\": train_loss,\n",
    "            \"ValLoss\": val_loss,\n",
    "        })\n",
    "\n",
    "        if batch_num % 100 == 0:\n",
    "            y_batch_decoded = tokenizer.batch_decode(y_val, skip_special_tokens=True)\n",
    "            val_ids_predictions = torch.argmax(val_pred, dim=-1)\n",
    "            val_pred_decoded = tokenizer.batch_decode(val_ids_predictions, skip_special_tokens=True)\n",
    "            print(f\"Iteration {batch_num}  |  TrainLoss: {train_loss:.4f} ValLoss: {val_loss:.4f}\")\n",
    "            for i in choices(range(BATCH_SIZE), k=3):\n",
    "                print(f\"Polish Annotation: {y_batch_decoded[i]}\")\n",
    "                print(f\"Prediction (Val): {val_pred_decoded[i]}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Batch</th>\n",
       "      <th>TrainLoss</th>\n",
       "      <th>ValLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.951061</td>\n",
       "      <td>9.484363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.768107</td>\n",
       "      <td>8.790740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.827914</td>\n",
       "      <td>8.473635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.619621</td>\n",
       "      <td>8.395632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8.096702</td>\n",
       "      <td>7.816197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>0.210911</td>\n",
       "      <td>1.576687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>0.171677</td>\n",
       "      <td>1.857374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>0.258021</td>\n",
       "      <td>1.296809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>0.112273</td>\n",
       "      <td>1.461502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0.167982</td>\n",
       "      <td>1.968619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch  Batch  TrainLoss   ValLoss\n",
       "0        1      1  10.951061  9.484363\n",
       "1        1      2   9.768107  8.790740\n",
       "2        1      3   8.827914  8.473635\n",
       "3        1      4   8.619621  8.395632\n",
       "4        1      5   8.096702  7.816197\n",
       "..     ...    ...        ...       ...\n",
       "735     20     33   0.210911  1.576687\n",
       "736     20     34   0.171677  1.857374\n",
       "737     20     35   0.258021  1.296809\n",
       "738     20     36   0.112273  1.461502\n",
       "739     20     37   0.167982  1.968619\n",
       "\n",
       "[740 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame.from_records(metrics_history)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"TrainLoss\", label=\"Training\")\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"ValLoss\", label=\"Validation\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), MODELS_DIR / \"transformer_v1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ").to(DEVICE)\n",
    "\n",
    "pretrained_weights = torch.load(MODELS_DIR / \"transformer_v1.pth\")\n",
    "translator.load_state_dict(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.bos_token_id=0\n",
      "tokenizer.eos_token_id=2\n",
      "tokenizer.pad_token_id=1\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tokenizer.bos_token_id=}\")\n",
    "print(f\"{tokenizer.eos_token_id=}\")\n",
    "print(f\"{tokenizer.pad_token_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, tokenizer, clip_seq_landmarks, max_tokens, device):\n",
    "    model.eval()\n",
    "    clip_seq_landmarks = clip_seq_landmarks.unsqueeze(0).to(device)\n",
    "    tokens_out = torch.full((1, max_tokens), tokenizer.pad_token_id).to(device)\n",
    "    tokens_out[0, 0] = tokenizer.bos_token_id\n",
    "    with torch.no_grad():\n",
    "        for n_token in range(1, max_tokens):\n",
    "            masks = create_masks(clip_seq_landmarks, tokens_out)\n",
    "            masks = [mask.to(device) for mask in masks]\n",
    "            predictions = transformer(clip_seq_landmarks, tokens_out, *masks)\n",
    "            next_token_prob_distribution = predictions[0][n_token]\n",
    "            next_token_index = next_token_prob_distribution.argmax().item()\n",
    "            if next_token_index == tokenizer.eos_token_id:\n",
    "                print(\"End of sentence token reached\")\n",
    "                break\n",
    "            tokens_out[0, n_token] = next_token_index\n",
    "    decoded_out = tokenizer.decode(tokens_out[0], skip_special_tokens=True)\n",
    "    return decoded_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_batch_idx=10\n",
      "random_batch_item_idx=3\n",
      "Annotation: Pracuję, nie mogę.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=34\n",
      "random_batch_item_idx=3\n",
      "Annotation: Żółty trójkąt mówi, że trzeba uważać, żeby nie spaść na dół na nawierzchnię.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=2\n",
      "random_batch_item_idx=12\n",
      "Annotation: Podchodzi do niego mały chłopiec, ale Charlie odpycha go od siebie nogą.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=11\n",
      "random_batch_item_idx=31\n",
      "Annotation: Wypadek.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=25\n",
      "random_batch_item_idx=10\n",
      "Annotation: Spokojnie.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=12\n",
      "random_batch_item_idx=11\n",
      "Annotation: Następny.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=28\n",
      "random_batch_item_idx=22\n",
      "Annotation: Ja widzę, jak się całują, denerwuję się.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=18\n",
      "random_batch_item_idx=26\n",
      "Annotation: I stawia go na głowie.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=34\n",
      "random_batch_item_idx=15\n",
      "Annotation: Dlaczego?\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n",
      "random_batch_idx=26\n",
      "random_batch_item_idx=13\n",
      "Annotation: Ja mogę trzeciego, idę tylko do kina.\n",
      "Translation: Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten Ten\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    random_batch_idx = np.random.randint(0, len(val_dl))\n",
    "    random_batch_item_idx = np.random.randint(0, BATCH_SIZE)\n",
    "    print(f\"{random_batch_idx=}\")\n",
    "    print(f\"{random_batch_item_idx=}\")\n",
    "\n",
    "    random_clip = list(val_dl)[random_batch_idx]\n",
    "\n",
    "    clip_seq_landmarks = random_clip[\"in_landmarks\"][random_batch_item_idx]\n",
    "    pl_annotation = tokenizer.decode(random_clip[\"out_polish_token_ids\"][random_batch_item_idx], skip_special_tokens=True)\n",
    "\n",
    "    translation = translate(translator, tokenizer, clip_seq_landmarks, max_tokens=MAX_SEQUENCE_LENGTH, device=DEVICE)\n",
    "\n",
    "    print(f\"Annotation: {pl_annotation}\")\n",
    "    print(f\"Translation: {translation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, N_LANDMARKS) ).to(DEVICE) # includes positional encoding\n",
    "out = encoder(x, self_attention_mask=None)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, D_MODEL) ).to(DEVICE)  # seq of frames (landmarks), batched; positional encoded\n",
    "y = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, MAX_SEQUENCE_LENGTH) ).to(DEVICE)  # batched tokens ids; positional encoded\n",
    "\n",
    "mask = torch.full([MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH] , float('-inf')).to(DEVICE)\n",
    "mask = torch.triu(mask, diagonal=1).to(DEVICE)\n",
    "\n",
    "decoder = Decoder(D_MODEL, FFN_HIDDEN, NUM_HEADS, DROP_PROB, NUM_LAYERS, MAX_SEQUENCE_LENGTH, VOCAB_SIZE).to(DEVICE)\n",
    "\n",
    "out = decoder(x, y, mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    d_model=D_MODEL,\n",
    "    ffn_hidden=FFN_HIDDEN,\n",
    "    num_heads=NUM_HEADS,\n",
    "    drop_prob=DROP_PROB,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn( (BATCH_SIZE, MAX_SEQUENCE_LENGTH, N_LANDMARKS) ).to(get_device())\n",
    "y = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, MAX_SEQUENCE_LENGTH) ).to(get_device())\n",
    "\n",
    "result = transformer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 50000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6741,  0.1794, -0.6542,  ...,  1.0046, -0.1190,  0.8754],\n",
       "         [-0.3435,  0.0124, -0.5958,  ..., -0.3289,  0.1823,  0.4486],\n",
       "         [ 0.3794,  0.1556,  0.2594,  ..., -1.0698, -0.5115,  0.9614],\n",
       "         ...,\n",
       "         [-0.0213, -0.8717,  0.4211,  ...,  0.0830, -0.2434, -0.1108],\n",
       "         [-0.0496, -0.5449,  0.3379,  ...,  0.3444, -0.8640, -0.3080],\n",
       "         [-0.8405, -0.1635, -0.1503,  ...,  0.6105, -0.4077, -0.9809]],\n",
       "\n",
       "        [[-0.2821, -0.2361, -0.1269,  ...,  0.0377, -0.6995,  0.2988],\n",
       "         [-0.8607, -0.1035,  0.1453,  ...,  0.0255, -1.2619,  0.4788],\n",
       "         [-0.0510,  0.4893,  1.4533,  ...,  1.4625, -1.0268,  0.3633],\n",
       "         ...,\n",
       "         [-0.2624, -0.3121,  0.1961,  ...,  0.9089, -0.4298, -0.3597],\n",
       "         [-0.4059, -0.4654, -0.2810,  ...,  0.1095, -0.9014,  0.1602],\n",
       "         [-1.1782, -0.0889, -0.4431,  ...,  0.5437, -1.1250, -0.1313]],\n",
       "\n",
       "        [[-0.3697, -0.3335,  0.1760,  ...,  1.0793, -0.5543,  0.1695],\n",
       "         [-0.4762,  0.3326,  0.5533,  ...,  0.1772, -0.3302,  0.0138],\n",
       "         [ 0.2020, -0.3608,  0.0279,  ..., -0.2508, -1.3803,  0.7538],\n",
       "         ...,\n",
       "         [-0.1746,  0.0875,  0.6715,  ...,  0.8109, -0.1787,  0.2919],\n",
       "         [-0.6235, -0.7715,  0.5470,  ...,  0.6282, -0.8289, -0.3279],\n",
       "         [-0.7952, -0.4301,  0.3657,  ...,  0.0343, -0.3811,  0.2461]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9561,  0.6538,  0.4602,  ...,  1.1385, -1.2085,  0.7699],\n",
       "         [ 0.3623, -0.7890,  0.0605,  ...,  0.3116, -1.0094,  1.2891],\n",
       "         [ 0.5946, -0.1972, -0.0898,  ...,  0.6300,  0.0271,  0.7353],\n",
       "         ...,\n",
       "         [ 0.5963,  0.0236,  0.6518,  ...,  0.3049, -1.2586, -0.2075],\n",
       "         [ 0.4086, -0.1042, -0.5786,  ...,  0.9487, -0.3312,  0.5077],\n",
       "         [-0.0298, -0.5615,  0.9676,  ...,  0.9254, -0.5134, -0.4709]],\n",
       "\n",
       "        [[-0.3184,  0.0513,  0.3660,  ...,  0.3353, -0.4168,  1.3229],\n",
       "         [-0.6718,  0.1830, -0.1557,  ...,  0.0562, -1.1758,  0.2628],\n",
       "         [ 0.5122, -0.3381,  0.2648,  ...,  0.1562, -0.6096,  0.3622],\n",
       "         ...,\n",
       "         [-0.8295, -1.0159, -0.2351,  ...,  0.7778, -0.2642,  0.3218],\n",
       "         [-0.6849, -0.7761, -0.2565,  ...,  0.4356, -1.1149,  0.2498],\n",
       "         [-0.0872, -1.0173,  0.6515,  ...,  0.1142, -0.3180, -0.1040]],\n",
       "\n",
       "        [[-0.0467,  0.2905,  0.2977,  ..., -0.0806,  0.1709,  0.0076],\n",
       "         [-0.1316,  0.8760, -0.5134,  ..., -0.2553,  0.3123, -0.0709],\n",
       "         [-0.0266, -0.1208,  0.2414,  ...,  0.4577, -1.0345,  0.7353],\n",
       "         ...,\n",
       "         [-0.2575, -0.0413,  0.2368,  ...,  0.8479, -0.3287, -0.2410],\n",
       "         [-0.7320, -0.3178,  0.4438,  ...,  1.0416, -0.1910, -0.8314],\n",
       "         [-0.5997,  0.1160,  0.3345,  ...,  0.4235, -0.7475, -0.4336]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', 2, 50000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer.pad_token_id = 1\n",
    "tokenizer.bos_token_id = 0\n",
    "tokenizer.eos_token_id = 2\n",
    "\n",
    "tokenizer.decode(2), tokenizer.eos_token_id, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
